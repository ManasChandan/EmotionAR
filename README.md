# EmotionAR
DeepLearning and Unity3D project
This project uses the LBPHF recognizer to recognize a particular person and using TensorFlow Keras, I created a model to detect the expression of the person, conclusively to detect the expression of a particular person. I send these in realtime data to the android app(made by Unity and Vuforia)using firebase. The program updates the values in every 10secs.
In the android application, I have tried to display the expression(emotion) of the particular person using emoji and AR ray cast properties.
Proposal: Any meeting hall can have the system installed in the door which could detect the emotion of the person entering and the head of the meeting with the application can know the emotion of the attendees and could thus act accordingly.
